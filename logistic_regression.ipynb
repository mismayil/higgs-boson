{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv' # TODO: download train data and supply path here \n",
    "y_train, X_train, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv' # TODO: download train data and supply path here \n",
    "_, X_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import preprocess\n",
    "tX_train, ty_train, tX_test, ty_test, cont_features = preprocess(X_train, y_train, X_test, imputable_th=0.3, encodable_min_th=0.3, encodable_max_th=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.06833197,  0.40768027, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.        ,  0.55250482,  0.54013641, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.        ,  3.19515553,  1.09655998, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.        ,  0.31931645, -0.13086367, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.        , -0.84532397, -0.30297338, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.        ,  0.66533608, -0.25352276, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250000, 24), (568238, 24))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_train.shape, tX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy : 72.93650000000001% reached at epoch 199\n",
      "Best Accuracy : 73.335% reached at epoch 199\n",
      "Best Accuracy : 72.70299999999999% reached at epoch 199\n",
      "Best Accuracy : 72.59299999999999% reached at epoch 199\n",
      "Best Accuracy : 73.251% reached at epoch 199\n",
      "Best Accuracy : 72.928% reached at epoch 199\n",
      "Best Accuracy : 73.31450000000001% reached at epoch 198\n",
      "Best Accuracy : 72.70100000000001% reached at epoch 199\n",
      "Best Accuracy : 72.613% reached at epoch 199\n",
      "Best Accuracy : 73.24249999999999% reached at epoch 199\n",
      "Best Accuracy : 72.963% reached at epoch 198\n",
      "Best Accuracy : 73.1585% reached at epoch 198\n",
      "Best Accuracy : 72.65% reached at epoch 199\n",
      "Best Accuracy : 72.696% reached at epoch 198\n",
      "Best Accuracy : 73.1405% reached at epoch 198\n",
      "Best Accuracy : 71.6365% reached at epoch 95\n",
      "Best Accuracy : 71.646% reached at epoch 77\n",
      "Best Accuracy : 71.334% reached at epoch 174\n",
      "Best Accuracy : 71.4155% reached at epoch 170\n",
      "Best Accuracy : 71.572% reached at epoch 99\n",
      "Best Accuracy : 69.462% reached at epoch 24\n",
      "Best Accuracy : 69.4605% reached at epoch 22\n",
      "Best Accuracy : 69.33% reached at epoch 37\n",
      "Best Accuracy : 69.388% reached at epoch 39\n",
      "Best Accuracy : 69.46% reached at epoch 31\n",
      "Best Accuracy : 78.072% reached at epoch 199\n",
      "Best Accuracy : 78.7775% reached at epoch 199\n",
      "Best Accuracy : 78.589% reached at epoch 197\n",
      "Best Accuracy : 77.85% reached at epoch 199\n",
      "Best Accuracy : 78.428% reached at epoch 199\n",
      "Best Accuracy : 78.0795% reached at epoch 198\n",
      "Best Accuracy : 78.765% reached at epoch 199\n",
      "Best Accuracy : 78.583% reached at epoch 199\n",
      "Best Accuracy : 77.864% reached at epoch 199\n",
      "Best Accuracy : 78.41550000000001% reached at epoch 196\n",
      "Best Accuracy : 78.033% reached at epoch 199\n",
      "Best Accuracy : 78.6585% reached at epoch 193\n",
      "Best Accuracy : 78.44149999999999% reached at epoch 197\n",
      "Best Accuracy : 77.952% reached at epoch 199\n",
      "Best Accuracy : 78.265% reached at epoch 199\n",
      "Best Accuracy : 76.1555% reached at epoch 128\n",
      "Best Accuracy : 76.4795% reached at epoch 76\n",
      "Best Accuracy : 76.2145% reached at epoch 88\n",
      "Best Accuracy : 76.1385% reached at epoch 134\n",
      "Best Accuracy : 76.113% reached at epoch 85\n",
      "Best Accuracy : 69.3475% reached at epoch 11\n",
      "Best Accuracy : 70.647% reached at epoch 10\n",
      "Best Accuracy : 71.3355% reached at epoch 10\n",
      "Best Accuracy : 70.975% reached at epoch 10\n",
      "Best Accuracy : 70.935% reached at epoch 10\n",
      "Best Accuracy : 77.647% reached at epoch 199\n",
      "Best Accuracy : 78.213% reached at epoch 187\n",
      "Best Accuracy : 78.4145% reached at epoch 198\n",
      "Best Accuracy : 77.285% reached at epoch 197\n",
      "Best Accuracy : 78.434% reached at epoch 199\n",
      "Best Accuracy : 77.63250000000001% reached at epoch 197\n",
      "Best Accuracy : 78.2345% reached at epoch 187\n",
      "Best Accuracy : 78.3845% reached at epoch 198\n",
      "Best Accuracy : 77.3385% reached at epoch 197\n",
      "Best Accuracy : 78.45299999999999% reached at epoch 199\n",
      "Best Accuracy : 77.6405% reached at epoch 197\n",
      "Best Accuracy : 78.277% reached at epoch 189\n",
      "Best Accuracy : 78.115% reached at epoch 196\n",
      "Best Accuracy : 77.57300000000001% reached at epoch 199\n",
      "Best Accuracy : 78.337% reached at epoch 185\n",
      "Best Accuracy : 75.226% reached at epoch 191\n",
      "Best Accuracy : 75.82% reached at epoch 95\n",
      "Best Accuracy : 75.002% reached at epoch 105\n",
      "Best Accuracy : 75.541% reached at epoch 189\n",
      "Best Accuracy : 75.41550000000001% reached at epoch 85\n",
      "Best Accuracy : 71.06099999999999% reached at epoch 32\n",
      "Best Accuracy : 71.0535% reached at epoch 44\n",
      "Best Accuracy : 71.7175% reached at epoch 18\n",
      "Best Accuracy : 70.9015% reached at epoch 24\n",
      "Best Accuracy : 70.4645% reached at epoch 12\n"
     ]
    }
   ],
   "source": [
    "from implementations import logistic_regression_cv\n",
    "weights, loss, lambda_, degree, accuracy, f1 = logistic_regression_cv(ty_train, tX_train, max_iters=200, cont_features=cont_features, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.23872524],\n",
       "        [-0.57155435],\n",
       "        [-0.00990512],\n",
       "        [ 0.38146168],\n",
       "        [ 0.80410591],\n",
       "        [-0.02636859],\n",
       "        [ 0.20541366],\n",
       "        [-0.29468863],\n",
       "        [ 0.2389753 ],\n",
       "        [ 0.67638841],\n",
       "        [-0.0524618 ],\n",
       "        [ 0.01153473],\n",
       "        [ 0.29985158],\n",
       "        [ 0.0679841 ],\n",
       "        [ 0.00284688],\n",
       "        [ 0.08168035],\n",
       "        [ 0.02530589],\n",
       "        [ 0.20573885],\n",
       "        [ 0.00455425],\n",
       "        [-0.107733  ],\n",
       "        [ 0.22853251],\n",
       "        [-0.21147431],\n",
       "        [ 0.09227908],\n",
       "        [-0.50184131],\n",
       "        [ 0.0614066 ],\n",
       "        [-0.33355662],\n",
       "        [ 0.02385781],\n",
       "        [ 0.01415927],\n",
       "        [ 0.00574094],\n",
       "        [ 0.26353548],\n",
       "        [-0.06885229],\n",
       "        [-0.09601186],\n",
       "        [-0.03304313],\n",
       "        [-0.01071263],\n",
       "        [-0.23095955],\n",
       "        [-0.05340245],\n",
       "        [ 0.00312328],\n",
       "        [ 0.02932327],\n",
       "        [-0.10396382],\n",
       "        [-0.12158887],\n",
       "        [-0.05631481],\n",
       "        [-0.29968226]]),\n",
       " 0.4657866117913868,\n",
       " 0.001,\n",
       " 2,\n",
       " 78.36600000000001,\n",
       " 0.7330741381554299)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, loss, lambda_, degree, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0/500\n",
      "Accuracy = 34.318799999999996%\n",
      "Loss = 5.256219006861961\n",
      "\n",
      "\n",
      "Iteration 10/500\n",
      "Accuracy = 60.977599999999995%\n",
      "Loss = 1.3556130430289726\n",
      "\n",
      "\n",
      "Iteration 20/500\n",
      "Accuracy = 66.6364%\n",
      "Loss = 0.7146489905288386\n",
      "\n",
      "\n",
      "Iteration 30/500\n",
      "Accuracy = 69.2048%\n",
      "Loss = 0.6174073431827\n",
      "\n",
      "\n",
      "Iteration 40/500\n",
      "Accuracy = 71.1688%\n",
      "Loss = 0.5695721260713025\n",
      "\n",
      "\n",
      "Iteration 50/500\n",
      "Accuracy = 72.86240000000001%\n",
      "Loss = 0.540001594431089\n",
      "\n",
      "\n",
      "Iteration 60/500\n",
      "Accuracy = 74.1148%\n",
      "Loss = 0.5204350926706494\n",
      "\n",
      "\n",
      "Iteration 70/500\n",
      "Accuracy = 75.1024%\n",
      "Loss = 0.506996866409422\n",
      "\n",
      "\n",
      "Iteration 80/500\n",
      "Accuracy = 75.87559999999999%\n",
      "Loss = 0.49753762151094827\n",
      "\n",
      "\n",
      "Iteration 90/500\n",
      "Accuracy = 76.42999999999999%\n",
      "Loss = 0.4906998332208967\n",
      "\n",
      "\n",
      "Iteration 100/500\n",
      "Accuracy = 76.80160000000001%\n",
      "Loss = 0.4856297105563596\n",
      "\n",
      "\n",
      "Iteration 110/500\n",
      "Accuracy = 77.1132%\n",
      "Loss = 0.48178422373616286\n",
      "\n",
      "\n",
      "Iteration 120/500\n",
      "Accuracy = 77.404%\n",
      "Loss = 0.47880549124432953\n",
      "\n",
      "\n",
      "Iteration 130/500\n",
      "Accuracy = 77.58040000000001%\n",
      "Loss = 0.4764532906805754\n",
      "\n",
      "\n",
      "Iteration 140/500\n",
      "Accuracy = 77.72200000000001%\n",
      "Loss = 0.47456267085117637\n",
      "\n",
      "\n",
      "Iteration 150/500\n",
      "Accuracy = 77.8336%\n",
      "Loss = 0.4730154166291708\n",
      "\n",
      "\n",
      "Iteration 160/500\n",
      "Accuracy = 77.9404%\n",
      "Loss = 0.4717335696195292\n",
      "\n",
      "\n",
      "Iteration 170/500\n",
      "Accuracy = 78.0204%\n",
      "Loss = 0.4706577991629283\n",
      "\n",
      "\n",
      "Iteration 180/500\n",
      "Accuracy = 78.0852%\n",
      "Loss = 0.469742956902547\n",
      "\n",
      "\n",
      "Iteration 190/500\n",
      "Accuracy = 78.1408%\n",
      "Loss = 0.4689557763144139\n",
      "\n",
      "\n",
      "Iteration 200/500\n",
      "Accuracy = 78.18%\n",
      "Loss = 0.46827469875232647\n",
      "\n",
      "\n",
      "Iteration 210/500\n",
      "Accuracy = 78.2256%\n",
      "Loss = 0.4676799292491664\n",
      "\n",
      "\n",
      "Iteration 220/500\n",
      "Accuracy = 78.2732%\n",
      "Loss = 0.46715680859369135\n",
      "\n",
      "\n",
      "Iteration 230/500\n",
      "Accuracy = 78.30799999999999%\n",
      "Loss = 0.46669287058606646\n",
      "\n",
      "\n",
      "Iteration 240/500\n",
      "Accuracy = 78.342%\n",
      "Loss = 0.4662795435551398\n",
      "\n",
      "\n",
      "Iteration 250/500\n",
      "Accuracy = 78.3672%\n",
      "Loss = 0.46590907710149176\n",
      "\n",
      "\n",
      "Iteration 260/500\n",
      "Accuracy = 78.378%\n",
      "Loss = 0.46557531457145584\n",
      "\n",
      "\n",
      "Iteration 270/500\n",
      "Accuracy = 78.3952%\n",
      "Loss = 0.46527306196908436\n",
      "\n",
      "\n",
      "Iteration 280/500\n",
      "Accuracy = 78.42280000000001%\n",
      "Loss = 0.46499730568138653\n",
      "\n",
      "\n",
      "Iteration 290/500\n",
      "Accuracy = 78.444%\n",
      "Loss = 0.4647438613647821\n",
      "\n",
      "\n",
      "Iteration 300/500\n",
      "Accuracy = 78.4648%\n",
      "Loss = 0.4645105595272016\n",
      "\n",
      "\n",
      "Iteration 310/500\n",
      "Accuracy = 78.4748%\n",
      "Loss = 0.46429444925581415\n",
      "\n",
      "\n",
      "Iteration 320/500\n",
      "Accuracy = 78.49080000000001%\n",
      "Loss = 0.46409389341673535\n",
      "\n",
      "\n",
      "Iteration 330/500\n",
      "Accuracy = 78.4892%\n",
      "Loss = 0.46390704910086333\n",
      "\n",
      "\n",
      "Iteration 340/500\n",
      "Accuracy = 78.4956%\n",
      "Loss = 0.4637322812969434\n",
      "\n",
      "\n",
      "Iteration 350/500\n",
      "Accuracy = 78.498%\n",
      "Loss = 0.46356818515010356\n",
      "\n",
      "\n",
      "Iteration 360/500\n",
      "Accuracy = 78.5124%\n",
      "Loss = 0.4634135500138565\n",
      "\n",
      "\n",
      "Iteration 370/500\n",
      "Accuracy = 78.5204%\n",
      "Loss = 0.4632673297270026\n",
      "\n",
      "\n",
      "Iteration 380/500\n",
      "Accuracy = 78.53999999999999%\n",
      "Loss = 0.46312861790878934\n",
      "\n",
      "\n",
      "Iteration 390/500\n",
      "Accuracy = 78.5604%\n",
      "Loss = 0.4629966273307352\n",
      "\n",
      "\n",
      "Iteration 400/500\n",
      "Accuracy = 78.556%\n",
      "Loss = 0.4628706417219408\n",
      "\n",
      "\n",
      "Iteration 410/500\n",
      "Accuracy = 78.5648%\n",
      "Loss = 0.4627498013359039\n",
      "\n",
      "\n",
      "Iteration 420/500\n",
      "Accuracy = 78.5784%\n",
      "Loss = 0.4626333323624714\n",
      "\n",
      "\n",
      "Iteration 430/500\n",
      "Accuracy = 78.5744%\n",
      "Loss = 0.46252135022188345\n",
      "\n",
      "\n",
      "Iteration 440/500\n",
      "Accuracy = 78.5776%\n",
      "Loss = 0.46241323991417255\n",
      "\n",
      "\n",
      "Iteration 450/500\n",
      "Accuracy = 78.5804%\n",
      "Loss = 0.4623088126239911\n",
      "\n",
      "\n",
      "Iteration 460/500\n",
      "Accuracy = 78.5844%\n",
      "Loss = 0.46220781049802684\n",
      "\n",
      "\n",
      "Iteration 470/500\n",
      "Accuracy = 78.5888%\n",
      "Loss = 0.46210995543373684\n",
      "\n",
      "\n",
      "Iteration 480/500\n",
      "Accuracy = 78.5896%\n",
      "Loss = 0.4620150009826032\n",
      "\n",
      "\n",
      "Iteration 490/500\n",
      "Accuracy = 78.60040000000001%\n",
      "Loss = 0.46192272830045417\n",
      "\n",
      "\n",
      "Best Accuracy : 78.6084% reached at epoch 498\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from implementations import reg_logistic_regression, build_poly\n",
    "tX_train_poly = build_poly(tX_train, degree=degree, cont_features=cont_features)\n",
    "weights, loss = reg_logistic_regression(ty_train, tX_train_poly, max_iters=500, lambda_=lambda_, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 24)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import build_poly\n",
    "tX_test_poly = build_poly(tX_test, degree, cont_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238, 42)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_test_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from implementations import predict_log_reg\n",
    "method = 'reg_logistic_regression'\n",
    "time = datetime.now().strftime('%Y%m%dH%H%M%S')\n",
    "OUTPUT_PATH = f'submissions/submission_{method}_{time}' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_log_reg(weights, tX_test_poly)\n",
    "y_pred[np.where(y_pred == 0)] = -1\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34e9dc8c9cd4c2e3341692c7f5472da17e27c062a0f2ac63648b60e63867ef4a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
