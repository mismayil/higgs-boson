{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full ML Pipeline\n",
    "This notebook contains the code for the Project 1 full ML pipeline from data loading to hyperparameter tuning and to prediction on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y_train, X_train, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv' \n",
    "_, X_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250000, 30), (568238, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have selected the Regularized Logistic Regression as the best model suited for our task, we will perform the following steps based on this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_zero, y_train_zero, X_train_one, y_train_one, X_train_many, y_train_many = split_by_jet_num(DATA_TRAIN_PATH, X_train, y_train)\n",
    "X_test_zero, ids_test_zero, X_test_one, ids_test_one, X_test_many, ids_test_many = split_by_jet_num(DATA_TRAIN_PATH, X_test, ids_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "Here we will tune our hyperparameters for the Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(X_train, y_train, X_test):\n",
    "    tX_train, ty_train, tX_test, _, cont_features = preprocess(X_train, y_train, X_test, imputable_th=0.5, encodable_th=1, switch_encoding=True)\n",
    "    param_grid = {\n",
    "        'max_iters': 1000,\n",
    "        'degree': list(range(1, 5)),\n",
    "        'lambda_': np.logspace(-3, 0, 4),\n",
    "        'gamma': [0.01, 0.1],\n",
    "        'cont_features': [cont_features]\n",
    "    }\n",
    "    return reg_logistic_regression_cv(ty_train, tX_train, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mismayil/Desktop/EPFL/ml-project-1-gradient_surfers/helpers.py:118: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp / (tp + fp)\n"
     ]
    }
   ],
   "source": [
    "metrics_zero, params_zero = tune_hyperparameters(X_train_zero, y_train_zero, X_test_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_one, params_one = tune_hyperparameters(X_train_one, y_train_one, X_test_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_many, params_many = tune_hyperparameters(X_train_many, y_train_many, X_test_many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'loss': 0.36910622237707635,\n",
       "  'accuracy': 83.86430223592906,\n",
       "  'f1_score': 0.6450241534035307},\n",
       " {'max_iters': 1000,\n",
       "  'degree': 3,\n",
       "  'lambda_': 0.001,\n",
       "  'gamma': 0.1,\n",
       "  'cont_features': (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_zero, params_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'loss': 0.4400778655095133,\n",
       "  'accuracy': 80.07430997876858,\n",
       "  'f1_score': 0.70956626219191},\n",
       " {'max_iters': 1000,\n",
       "  'degree': 3,\n",
       "  'lambda_': 0.001,\n",
       "  'gamma': 0.1,\n",
       "  'cont_features': (1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22)})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_one, params_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'loss': 0.406439698330773,\n",
       "  'accuracy': 82.17357640599704,\n",
       "  'f1_score': 0.8025500180718208},\n",
       " {'max_iters': 1000,\n",
       "  'degree': 3,\n",
       "  'lambda_': 0.001,\n",
       "  'gamma': 0.1,\n",
       "  'cont_features': (1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29)})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_many, params_many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model with tuned hyperparameters and make predictions\n",
    "We can see that tuned hyperparameter values for all 3 models are in fact the same i.e. degree=3, lambda_=0.001, gamma=0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(X_train, y_train, X_test, max_iters=3000, degree=2, lambda_=0.01, gamma=0.01, imputable_th=1, encodable_th=0):\n",
    "    tX_train, ty_train, tX_test, _, cont_features = preprocess(X_train, y_train, X_test, imputable_th=imputable_th, encodable_th=encodable_th, switch_encoding=True)\n",
    "    tX_train_poly = build_poly(tX_train, degree=degree, cont_features=cont_features)\n",
    "    weights, loss = reg_logistic_regression(ty_train, tX_train_poly, max_iters=max_iters, lambda_=lambda_, gamma=gamma)\n",
    "    tX_test_poly = build_poly(tX_test, degree=degree, cont_features=cont_features)\n",
    "    y_pred = predict_logistic(weights, tX_test_poly)\n",
    "    y_pred = replace_values(y_pred, from_val=0, to_val=-1)\n",
    "    return y_pred, weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_zero, weights_zero, loss_zero = train_predict(X_train_zero, y_train_zero, X_test_zero, max_iters=3000, gamma=params_zero['gamma'],\n",
    "                                                     degree=params_zero['degree'], lambda_=params_zero['lambda_'], imputable_th=1, encodable_th=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_one, weights_one, loss_one = train_predict(X_train_one, y_train_one, X_test_one, max_iters=3000, gamma=params_one['gamma'],\n",
    "                                                  degree=params_one['degree'], lambda_=params_one['lambda_'], imputable_th=1, encodable_th=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_many, weights_many, loss_many = train_predict(X_train_many, y_train_many, X_test_many, max_iters=3000, gamma=params_many['gamma'],\n",
    "                                                     degree=params_many['degree'], lambda_=params_many['lambda_'], imputable_th=1, encodable_th=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 82.19813630204901\n"
     ]
    }
   ],
   "source": [
    "a = X_train_zero.shape[0]\n",
    "b = X_train_one.shape[0] \n",
    "c = X_train_many.shape[0]\n",
    "avg_accuracy = ((metrics_zero['accuracy']*a) +  (metrics_one['accuracy']*b) + (metrics_many['accuracy']*c))/(a+b+c)\n",
    "\n",
    "print(f\"Average accuracy: {avg_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "y_pred = np.vstack([y_pred_zero, y_pred_one, y_pred_many])\n",
    "ids_test = np.hstack([ids_test_zero, ids_test_one, ids_test_many])\n",
    "method = 'reg_logistic_regression'\n",
    "time = datetime.now().strftime('%Y%m%dH%H%M%S')\n",
    "OUTPUT_PATH = f'submissions/submission_{method}_{time}'\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "34e9dc8c9cd4c2e3341692c7f5472da17e27c062a0f2ac63648b60e63867ef4a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
